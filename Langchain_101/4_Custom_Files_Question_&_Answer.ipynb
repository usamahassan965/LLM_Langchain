{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install faiss-cpu chromadb\n",
        "!pip install unstructured\n",
        "!pip install -q InstructorEmbedding sentence_transformers ### requirements for instructor embeddings"
      ],
      "metadata": {
        "id": "sgkIbGgS1qB9",
        "outputId": "68569d4d-ce99-45ba-92b8-e98de4f308f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sgkIbGgS1qB9",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.11.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.11.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.9.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.3)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2023.12.11)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.23.5)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.5.2)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.11.17)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ad66c9aa",
      "metadata": {
        "id": "ad66c9aa",
        "outputId": "db8692b7-bbf3-400c-ecba-00ce883c1f7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "import magic\n",
        "import os\n",
        "import nltk\n",
        "\n",
        "#openai_api_key = os.getenv(\"OPENAI_API_KEY\", \"YourAPIKey\")\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# pip install unstructured\n",
        "# Other dependencies to install https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/unstructured_file.html\n",
        "# pip install python-magic-bin\n",
        "# pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/PaulGrahamEssaySmall.zip'"
      ],
      "metadata": {
        "id": "XKgncXuz3LHm"
      },
      "id": "XKgncXuz3LHm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e8a28a08",
      "metadata": {
        "id": "e8a28a08"
      },
      "outputs": [],
      "source": [
        "# Get your loader ready\n",
        "loader = DirectoryLoader('PaulGrahamEssaySmall/', glob='**/*.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6a9740d9",
      "metadata": {
        "id": "6a9740d9"
      },
      "outputs": [],
      "source": [
        "# Load up your text into documents\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3153f864",
      "metadata": {
        "id": "3153f864"
      },
      "outputs": [],
      "source": [
        "# Get your text splitter ready\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a792c6fb",
      "metadata": {
        "id": "a792c6fb"
      },
      "outputs": [],
      "source": [
        "# Split your documents into texts\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d2cad0de",
      "metadata": {
        "id": "d2cad0de",
        "outputId": "bbb79688-ff18-43ad-aa5d-c305bca48c4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import trange\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ],
      "source": [
        "# # Turn your texts into embeddings\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "\n",
        "# Initialize instructor embeddings using the Hugging Face model\n",
        "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
        "# embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "734ed265",
      "metadata": {
        "id": "734ed265"
      },
      "outputs": [],
      "source": [
        "# Get your docsearch ready\n",
        "docsearch = FAISS.from_documents(texts, instructor_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "66826924",
      "metadata": {
        "id": "66826924"
      },
      "outputs": [],
      "source": [
        "# # Load up your LLM\n",
        "from langchain.llms import GooglePalm\n",
        "\n",
        "api_key = 'AIzaSyDx8l7u6z-0Y9XTkDKiP57tykOPLDm3CtA'\n",
        "\n",
        "llm = GooglePalm(google_api_key=api_key, temperature=0)\n",
        "# llm = OpenAI(openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "817a0ece",
      "metadata": {
        "id": "817a0ece"
      },
      "outputs": [],
      "source": [
        "# Create your Retriever\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "20b81063",
      "metadata": {
        "id": "20b81063",
        "outputId": "d6ada8d7-876d-4092-f9b5-d07f2366229f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a model for what programming is tending to become in our own time'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Run a query\n",
        "query = \"What did McCarthy discover?\"\n",
        "qa.run(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22231c5",
      "metadata": {
        "id": "f22231c5"
      },
      "source": [
        "### Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "694343cb",
      "metadata": {
        "id": "694343cb"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                chain_type=\"stuff\",\n",
        "                                retriever=docsearch.as_retriever(),\n",
        "                                return_source_documents=True)\n",
        "query = \"What did McCarthy discover?\"\n",
        "result = qa({\"query\": query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bec53323",
      "metadata": {
        "id": "bec53323",
        "outputId": "3d6e6c55-3161-4931-e6a0-8e91518e641b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a model for what programming is tending to become in our own time'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "result['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "32246ae3",
      "metadata": {
        "id": "32246ae3",
        "outputId": "25d83b0b-80c6-4345-d623-4d13bab37bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='May 2001\\n\\n(I wrote this article to help myself understand exactly\\n\\nwhat McCarthy discovered. You don\\'t need to know this stuff\\n\\nto program in Lisp, but it should be helpful to\\n\\nanyone who wants to\\n\\nunderstand the essence of Lisp \\x97 both in the sense of its\\n\\norigins and its semantic core. The fact that it has such a core\\n\\nis one of Lisp\\'s distinguishing features, and the reason why,\\n\\nunlike other languages, Lisp has dialects. )In 1960, John\\n\\nMcCarthy published a remarkable paper in\\n\\nwhich he did for programming something like what Euclid did for\\n\\ngeometry. He showed how, given a handful of simple\\n\\noperators and a notation for functions, you can\\n\\nbuild a whole programming language.\\n\\nHe called this language Lisp, for \"List Processing,\"\\n\\nbecause one of his key ideas was to use a simple\\n\\ndata structure called a list for both\\n\\ncode and data.It\\'s worth understanding what McCarthy discovered, not\\n\\njust as a landmark in the history of computers, but as', metadata={'source': 'PaulGrahamEssaySmall/rootsoflisp.txt'}),\n",
              " Document(page_content=\"itself. To understand what McCarthy meant by this,\\n\\nwe're going to retrace his steps, with his mathematical\\n\\nnotation translated into running Common Lisp code.\", metadata={'source': 'PaulGrahamEssaySmall/rootsoflisp.txt'}),\n",
              " Document(page_content=\"a model for what programming is tending to become in\\n\\nour own time. It seems to me that there have been\\n\\ntwo really clean, consistent models of programming so\\n\\nfar: the C model and the Lisp model.\\n\\nThese two seem points of high ground, with swampy lowlands\\n\\nbetween them. As computers have grown more powerful,\\n\\nthe new languages being developed have been moving\\n\\nsteadily toward the Lisp model. A popular recipe\\n\\nfor new programming languages in the past 20 years\\n\\nhas been to take the C model of computing and add to\\n\\nit, piecemeal, parts taken from the Lisp model,\\n\\nlike runtime typing and garbage collection.In this article I'm going to try to explain in the\\n\\nsimplest possible terms what McCarthy discovered.\\n\\nThe point is not just to learn about an interesting\\n\\ntheoretical result someone figured out forty years ago,\\n\\nbut to show where languages are heading.\\n\\nThe unusual thing about Lisp \\x97 in fact, the defining\\n\\nquality of Lisp \\x97 is that it can be written in\", metadata={'source': 'PaulGrahamEssaySmall/rootsoflisp.txt'}),\n",
              " Document(page_content=\"January 2017Because biographies of famous scientists tend to\\n\\nedit out their mistakes, we underestimate the\\n\\ndegree of risk they were willing to take.\\n\\nAnd because anything a famous scientist did that\\n\\nwasn't a mistake has probably now become the\\n\\nconventional wisdom, those choices don't\\n\\nseem risky either.Biographies of Newton, for example, understandably focus\\n\\nmore on physics than alchemy or theology.\\n\\nThe impression we get is that his unerring judgment\\n\\nled him straight to truths no one else had noticed.\\n\\nHow to explain all the time he spent on alchemy\\n\\nand theology? Well, smart people are often kind of\\n\\ncrazy.But maybe there is a simpler explanation. Maybe\\n\\nthe smartness and the craziness were not as separate\\n\\nas we think. Physics seems to us a promising thing\\n\\nto work on, and alchemy and theology obvious wastes\\n\\nof time. But that's because we know how things\\n\\nturned out. In Newton's day the three problems\\n\\nseemed roughly equally promising. No one knew yet\", metadata={'source': 'PaulGrahamEssaySmall/disc.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "result['source_documents']"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}