{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install google-search-results\n",
        "!pip install wolframalpha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZXkIVcYvBRS",
        "outputId": "7211ed40-6f8a-46a9-e825-d0e4690956ae"
      },
      "id": "XZXkIVcYvBRS",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2023.11.17)\n",
            "Collecting wolframalpha\n",
            "  Downloading wolframalpha-5.0.0-py3-none-any.whl (7.5 kB)\n",
            "Collecting xmltodict (from wolframalpha)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from wolframalpha) (10.1.0)\n",
            "Collecting jaraco.context (from wolframalpha)\n",
            "  Downloading jaraco.context-4.3.0-py3-none-any.whl (5.3 kB)\n",
            "Installing collected packages: xmltodict, jaraco.context, wolframalpha\n",
            "Successfully installed jaraco.context-4.3.0 wolframalpha-5.0.0 xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5170bf5b",
      "metadata": {
        "id": "5170bf5b"
      },
      "source": [
        "# Agents - Make OpenAI Do Things For you"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d9faa06",
      "metadata": {
        "id": "8d9faa06"
      },
      "source": [
        "*[Source](https://langchain.readthedocs.io/en/latest/modules/agents/getting_started.html)*\n",
        "* **Agent** - Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\n",
        "\n",
        "Parameters when creating an agent:\n",
        "* **Tool:** A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains. The interface for a tool is currently a function that is expected to have a string as an input, with a string as an output.\n",
        "* **LLM:** The language model powering the agent.\n",
        "* **Agent:** The agent to use. This should be a string that references a support agent class. Because this notebook focuses on the simplest, highest level API, this only covers using the standard supported agents. If you want to implement a custom agent, see the documentation for custom agents (coming soon)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7f247903",
      "metadata": {
        "id": "7f247903"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bd3670a",
      "metadata": {
        "id": "0bd3670a"
      },
      "source": [
        "### List of Tools\n",
        "1. **python_repl -** A Python shell. Use this to execute python commands. Input should be a valid python command. If you expect output it should be printed out.\n",
        "2. **serpapi [Complete] -** A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
        "3. **wolfram-alpha [Complete] -** A wolfram alpha search engine. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query.\n",
        "4. **requests -** A portal to the internet. Use this when you need to get specific content from a site. Input should be a specific url, and the output will be all the text on that page.\n",
        "5. **terminal -** Executes commands in a terminal. Input should be valid commands, and the output will be any output from running that command.\n",
        "6. **pal-math -** A language model that is excellent at solving complex word math problems. Input should be a fully worded hard word math problem.\n",
        "7. **pal-colored-objects -** A language model that is wonderful at reasoning about position and the color attributes of objects. Input should be a fully worded hard reasoning problem. Make sure to include all information about the objects AND the final question you want to answer.\n",
        "8. **llm-math -** Useful for when you need to answer questions about math.\n",
        "9. **open-meteo-api -** Useful for when you want to get weather information from the OpenMeteo API. The input should be a question in natural language that this API can answer.\n",
        "10. **news-api -** Use this when you want to get information about the top headlines of current news stories. The input should be a question in natural language that this API can answer.\n",
        "11. **tmdb-api -** Useful for when you want to get information from The Movie Database. The input should be a question in natural language that this API can answer.\n",
        "12. **google-search -** A wrapper around Google Search. Useful for when you need to answer questions about current events. Input should be a search query.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83032dcf",
      "metadata": {
        "id": "83032dcf"
      },
      "source": [
        "### 2. SERP API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0c90ba74",
      "metadata": {
        "id": "0c90ba74"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = \"...\"\n",
        "os.environ['SERPAPI_API_KEY'] = \"1f57468c55e264dc45f088aa33535aecad4ff28252ebe153501cf86d1ea70f28\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d0f2fd44",
      "metadata": {
        "id": "d0f2fd44"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import GooglePalm\n",
        "\n",
        "api_key = 'AIzaSyDx8l7u6z-0Y9XTkDKiP57tykOPLDm3CtA'\n",
        "\n",
        "llm = GooglePalm(google_api_key=api_key, temperature=0)\n",
        "#llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f26a0dd5",
      "metadata": {
        "id": "f26a0dd5"
      },
      "outputs": [],
      "source": [
        "tool_names = [\"serpapi\"]\n",
        "tools = load_tools(tool_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e8a35518",
      "metadata": {
        "id": "e8a35518"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "829a2d67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "829a2d67",
        "outputId": "4c229dcd-2df2-4677-d2a1-50ab849fa204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to search for LangChain\n",
            "Action: Search\n",
            "Action Input: LangChain\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[\"LangChain is a framework designed to simplify the creation of applications using large language models. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\", 'LangChain kgmid: /g/11kjpl7_60.', 'LangChain initial_release_date: October 2022.', 'LangChain developer_s: Harrison Chase.', 'LangChain license: MIT License.', 'LangChain stable_release: 0.0.337 / 17 November 2023; 24 days ago.', 'LangChain written_in: Python and JavaScript.', \"LangChain's flexible abstractions and extensive toolkit unlocks developers to build context-aware, reasoning LLM applications.\", 'LangChain is a framework for developing applications powered by language models. It enables applications that: Are context-aware: connect a language model to ...', 'LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, ...', 'Memory refers to persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, ...', \"LangChain uses the power of AI large language models combined with data sources to create quite powerful apps. Read how it works and how it's used.\", 'LangChain is an open-source Python library that enables anyone who can write code to build LLM-powered applications. The package provides a generic interface to ...', 'At its core, LangChain is a framework built around LLMs. We can use it for chatbots, Generative Question-Answering (GQA), summarization, and much more.']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: LangChain is a framework designed to simplify the creation of applications using large language models.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain is a framework designed to simplify the creation of applications using large language models.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "agent.run(\"What is LangChain?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b4cc45f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "b4cc45f6",
        "outputId": "cb87d7dd-4f0b-4ca2-cbec-b2281ab96807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find the ceo of pipe\n",
            "Action: Search\n",
            "Action Input: who is the ceo of pipe\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mLuke Voiles\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Luke Voiles\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Luke Voiles'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Input should be a search query.\n",
        "agent.run(\"who is the ceo of pipe?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1869cabc",
      "metadata": {
        "id": "1869cabc"
      },
      "source": [
        "### 3. Wolfram Alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0fd02098",
      "metadata": {
        "id": "0fd02098"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "\n",
        "# import os\n",
        "# pip install wolframalpha\n",
        "# os.environ['OPENAI_API_KEY'] = \"...\"\n",
        "os.environ['WOLFRAM_ALPHA_APPID'] = \"RQYA3L-8GV7AJ97V5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a96dfdd",
      "metadata": {
        "id": "7a96dfdd"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1ba4200b",
      "metadata": {
        "id": "1ba4200b"
      },
      "outputs": [],
      "source": [
        "tool_names = [\"wolfram-alpha\"]\n",
        "tools = load_tools(tool_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "4716e3a8",
      "metadata": {
        "id": "4716e3a8"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e0d255",
      "metadata": {
        "id": "89e0d255"
      },
      "outputs": [],
      "source": [
        "# Input should be a search query.\n",
        "\n",
        "agent.run(\"What is the asthenosphere?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c98c29",
      "metadata": {
        "id": "86c98c29"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}